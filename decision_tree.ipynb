{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Final Project\n",
    "## Authors:\n",
    "- Taylor Tucker\n",
    "- Virginia Weston\n",
    "- Tina Jin\n",
    "- Jeffrey Bradley\n",
    "\n",
    "## Code for decision trees  and random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import statements"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing the dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./cleaned_data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "   Unnamed: 0  Number of Bachelor's Degrees  Percent Financial Aid  \\\n0           0                         208.0                  100.0   \n1           1                         310.0                  100.0   \n2           2                         398.0                  100.0   \n3           3                         382.0                  100.0   \n4           4                          61.0                   97.0   \n\n   Average Amount of Aid  Retention Rate  Enrollment  Percent Women  \\\n0                32400.0            79.0         996           99.0   \n1                40855.0            75.0        1533           54.0   \n2                39796.0            68.0        1912           60.0   \n3                38689.0            82.0        1771           56.0   \n4                10055.0            37.0         698           45.0   \n\n   Percent In State  Percent Out of State  Percent Foreign  ...  \\\n0              59.0                  36.0              4.0  ...   \n1              66.0                  32.0              1.0  ...   \n2              53.0                  46.0              1.0  ...   \n3              50.0                  45.0              4.0  ...   \n4              64.0                  34.0              0.0  ...   \n\n   Graduation Rate  Percent Awarded  Total Staff  Instructional Staff  \\\n0             69.0             66.0        357.0                105.0   \n1             64.0             61.0        435.0                132.0   \n2             51.0             48.0        355.0                123.0   \n3             74.0             70.0        426.0                160.0   \n4             31.0             10.0        115.0                 41.0   \n\n   SA Staff  Librarian Staff  Percent Books  Percent Digital  \\\n0      56.0             62.0             41               12   \n1      21.0             27.0             37               54   \n2      17.0             21.0             28               13   \n3      41.0             50.0             27               46   \n4       4.0              7.0             20               76   \n\n   Percent Admitted  Total Price  \n0              70.0      55625.0  \n1              68.0      59470.0  \n2              62.0      60636.0  \n3              64.0      63180.0  \n4              64.0      23170.0  \n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Number of Bachelor's Degrees</th>\n      <th>Percent Financial Aid</th>\n      <th>Average Amount of Aid</th>\n      <th>Retention Rate</th>\n      <th>Enrollment</th>\n      <th>Percent Women</th>\n      <th>Percent In State</th>\n      <th>Percent Out of State</th>\n      <th>Percent Foreign</th>\n      <th>...</th>\n      <th>Graduation Rate</th>\n      <th>Percent Awarded</th>\n      <th>Total Staff</th>\n      <th>Instructional Staff</th>\n      <th>SA Staff</th>\n      <th>Librarian Staff</th>\n      <th>Percent Books</th>\n      <th>Percent Digital</th>\n      <th>Percent Admitted</th>\n      <th>Total Price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>208.0</td>\n      <td>100.0</td>\n      <td>32400.0</td>\n      <td>79.0</td>\n      <td>996</td>\n      <td>99.0</td>\n      <td>59.0</td>\n      <td>36.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>69.0</td>\n      <td>66.0</td>\n      <td>357.0</td>\n      <td>105.0</td>\n      <td>56.0</td>\n      <td>62.0</td>\n      <td>41</td>\n      <td>12</td>\n      <td>70.0</td>\n      <td>55625.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>310.0</td>\n      <td>100.0</td>\n      <td>40855.0</td>\n      <td>75.0</td>\n      <td>1533</td>\n      <td>54.0</td>\n      <td>66.0</td>\n      <td>32.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>64.0</td>\n      <td>61.0</td>\n      <td>435.0</td>\n      <td>132.0</td>\n      <td>21.0</td>\n      <td>27.0</td>\n      <td>37</td>\n      <td>54</td>\n      <td>68.0</td>\n      <td>59470.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>398.0</td>\n      <td>100.0</td>\n      <td>39796.0</td>\n      <td>68.0</td>\n      <td>1912</td>\n      <td>60.0</td>\n      <td>53.0</td>\n      <td>46.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>51.0</td>\n      <td>48.0</td>\n      <td>355.0</td>\n      <td>123.0</td>\n      <td>17.0</td>\n      <td>21.0</td>\n      <td>28</td>\n      <td>13</td>\n      <td>62.0</td>\n      <td>60636.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>382.0</td>\n      <td>100.0</td>\n      <td>38689.0</td>\n      <td>82.0</td>\n      <td>1771</td>\n      <td>56.0</td>\n      <td>50.0</td>\n      <td>45.0</td>\n      <td>4.0</td>\n      <td>...</td>\n      <td>74.0</td>\n      <td>70.0</td>\n      <td>426.0</td>\n      <td>160.0</td>\n      <td>41.0</td>\n      <td>50.0</td>\n      <td>27</td>\n      <td>46</td>\n      <td>64.0</td>\n      <td>63180.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>61.0</td>\n      <td>97.0</td>\n      <td>10055.0</td>\n      <td>37.0</td>\n      <td>698</td>\n      <td>45.0</td>\n      <td>64.0</td>\n      <td>34.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>31.0</td>\n      <td>10.0</td>\n      <td>115.0</td>\n      <td>41.0</td>\n      <td>4.0</td>\n      <td>7.0</td>\n      <td>20</td>\n      <td>76</td>\n      <td>64.0</td>\n      <td>23170.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 21 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I cannot use classifier to guess a continuous target variable. Therefore, for the classifier models, I will need to create\n",
    "different classes for the target. I will do this by making classes that exist between $10,000 intervals. This will look like\n",
    "0-10,000, 10,000-20,000, 20,000-30,000, etc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76947.0\n",
      "16700.0\n"
     ]
    }
   ],
   "source": [
    "print(max(df[\"Total Price\"]))\n",
    "print(min(df[\"Total Price\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see from above that the max price of a school is 76,947 and the minimum is 16,700. Therefore, I will set the boundaries\n",
    "starting at 10,0000-20,000 and ending at 70,000-80,000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Total Price\n",
      "0  50,000-60,000\n",
      "1  50,000-60,000\n",
      "2  60,000-70,000\n",
      "3  60,000-70,000\n",
      "4  20,000-30,000\n"
     ]
    }
   ],
   "source": [
    "classified_prices = []\n",
    "for i in range(len(df[\"Total Price\"])):\n",
    "    if 10000 <= df[\"Total Price\"].iloc[i] < 20000:\n",
    "        classified_prices.append(\"10,000-20,000\")\n",
    "    elif 20000 <= df[\"Total Price\"].iloc[i] < 30000:\n",
    "        classified_prices.append(\"20,000-30,000\")\n",
    "    elif 30000 <= df[\"Total Price\"].iloc[i] < 40000:\n",
    "        classified_prices.append(\"30,000-40,000\")\n",
    "    elif 40000 <= df[\"Total Price\"].iloc[i] < 50000:\n",
    "        classified_prices.append(\"40,000-50,000\")\n",
    "    elif 50000 <= df[\"Total Price\"].iloc[i] < 60000:\n",
    "        classified_prices.append(\"50,000-60,000\")\n",
    "    elif 60000 <= df[\"Total Price\"].iloc[i] < 70000:\n",
    "        classified_prices.append(\"60,000-70,000\")\n",
    "    elif 70000 <= df[\"Total Price\"].iloc[i] < 80000:\n",
    "        classified_prices.append(\"70,000-80,000\")\n",
    "\n",
    "if len(classified_prices) == len(df[\"Total Price\"]):\n",
    "    classified_target = pd.DataFrame(classified_prices, columns=[\"Total Price\"])\n",
    "    print(classified_target.head())\n",
    "else:\n",
    "    print(\"Error in classifying\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, quick cleaning of the discreet dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "df_discreet = df.drop([\"Total Price\"], axis=1)\n",
    "df_discreet = pd.concat((df_discreet, classified_target), axis=1)\n",
    "df_discreet.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "df_discreet.head()\n",
    "df_discreet.to_csv(\"./cleaned_data_discreet.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating x and y for the DataFrames"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "x_d = df_discreet.iloc[:, :-1]\n",
    "y_d = df_discreet.iloc[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train test split 70-30"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_d, y_d, shuffle=True, test_size=0.3, random_state=1)\\"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating Pipelines for both"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "pl_dt = make_pipeline(StandardScaler(), MinMaxScaler(), DecisionTreeClassifier(), verbose=True)\n",
    "pl_rf = make_pipeline(StandardScaler(), MinMaxScaler(), RandomForestClassifier(), verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Establishing parameters for Grid Search"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "criteria = [\"gini\", \"entropy\"]\n",
    "dt_max_depth = [2, 3, 4, 5, 6, 7, 8]\n",
    "rf_max_depth = [i for i in range(100, 600, 100)]\n",
    "n_ests = [i for i in range(50, 551, 50)]\n",
    "\n",
    "grid_dt = {'decisiontreeclassifier__criterion': criteria,\n",
    "            'decisiontreeclassifier__max_depth': dt_max_depth}\n",
    "\n",
    "grid_rf = {'randomforestclassifier__criterion': criteria,\n",
    "           'randomforestclassifier__max_depth': rf_max_depth,\n",
    "           'randomforestclassifier__n_estimators': n_ests}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating Grid search objects, using 'accuracy' as the score since other metrics, like f1 and recall, require a\n",
    "binary clasification to function. Therefore, we are left with 'accuracy'."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "gs_dt = GridSearchCV(estimator=pl_dt, param_grid=grid_dt, scoring='accuracy', refit=True, cv=10, n_jobs=-1, verbose=True)\n",
    "gs_rf = GridSearchCV(estimator=pl_rf, param_grid=grid_rf, scoring='accuracy', refit=True, cv=10, n_jobs=-1, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fitting the grid searches to the training data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 14 candidates, totalling 140 fits\n",
      "[Pipeline] .... (step 1 of 3) Processing standardscaler, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing minmaxscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing decisiontreeclassifier, total=   0.0s\n",
      "DecisionTreeRegressor:\n",
      "Best Training Score: 0.5275000000000001\n",
      "Best Parameters: {'decisiontreeclassifier__criterion': 'entropy', 'decisiontreeclassifier__max_depth': 5}\n",
      "Best Testing Score: 0.6176470588235294\n",
      "\n",
      "Fitting 10 folds for each of 110 candidates, totalling 1100 fits\n",
      "[Pipeline] .... (step 1 of 3) Processing standardscaler, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing minmaxscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing randomforestclassifier, total=   0.3s\n",
      "RandomForestRegressor:\n",
      "Best Training Score: 0.6116666666666666\n",
      "Best Parameters: {'randomforestclassifier__criterion': 'gini', 'randomforestclassifier__max_depth': 200, 'randomforestclassifier__n_estimators': 200}\n",
      "Best Testing Score: 0.6323529411764706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:    2.6s finished\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done 474 tasks      | elapsed:   54.5s\n",
      "[Parallel(n_jobs=-1)]: Done 824 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1100 out of 1100 | elapsed:  2.2min finished\n"
     ]
    }
   ],
   "source": [
    "gs_dt.fit(x_train, y_train)\n",
    "print(\"DecisionTreeRegressor:\")\n",
    "print(\"Best Training Score:\", gs_dt.best_score_)\n",
    "print(\"Best Parameters:\", gs_dt.best_params_)\n",
    "print(\"Best Testing Score:\", gs_dt.score(x_test, y_test))\n",
    "print()\n",
    "\n",
    "gs_rf.fit(x_train, y_train)\n",
    "print(\"RandomForestRegressor:\")\n",
    "print(\"Best Training Score:\", gs_rf.best_score_)\n",
    "print(\"Best Parameters:\", gs_rf.best_params_)\n",
    "print(\"Best Testing Score:\", gs_rf.score(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the accuracy is really not great... I hypothesize that a part of this 63% testing accuracy comes\n",
    "from confounding variable. Therefore, I will copy the above code and run it, however change the x values to the best\n",
    "features described in the scaling_selection and README files."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "df_discreet = pd.read_csv(\"./cleaned_data_discreet.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating x and y for the DataFrames"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "x_d = df_discreet[[\"Average Amount of Aid\", \"Percent Financial Aid\", \"Percent Awarded\", \"Total Staff\", \"Graduation Rate\",\n",
    "                    \"Percent Admitted\", \"Number of Bachelor's Degrees\"]]\n",
    "y_d = df_discreet.iloc[:, -1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train test split 70-30"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_d, y_d, shuffle=True, test_size=0.3, random_state=1)\\"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating Pipelines for both"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "pl_dt = make_pipeline(StandardScaler(), MinMaxScaler(), DecisionTreeClassifier(), verbose=True)\n",
    "pl_rf = make_pipeline(StandardScaler(), MinMaxScaler(), RandomForestClassifier(), verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Establishing parameters for Grid Search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "criteria = [\"gini\", \"entropy\"]\n",
    "dt_max_depth = [2, 3, 4, 5, 6, 7, 8]\n",
    "rf_max_depth = [i for i in range(100, 600, 100)]\n",
    "n_ests = [i for i in range(50, 551, 50)]\n",
    "\n",
    "grid_dt = {'decisiontreeclassifier__criterion': criteria,\n",
    "            'decisiontreeclassifier__max_depth': dt_max_depth}\n",
    "\n",
    "grid_rf = {'randomforestclassifier__criterion': criteria,\n",
    "           'randomforestclassifier__max_depth': rf_max_depth,\n",
    "           'randomforestclassifier__n_estimators': n_ests}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating Grid search objects, using 'accuracy' as the score since other metrics, like f1 and recall, require a\n",
    "binary clasification to function. Therefore, we are left with 'accuracy'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "gs_dt = GridSearchCV(estimator=pl_dt, param_grid=grid_dt, scoring='accuracy', refit=True, cv=10, n_jobs=-1, verbose=True)\n",
    "gs_rf = GridSearchCV(estimator=pl_rf, param_grid=grid_rf, scoring='accuracy', refit=True, cv=10, n_jobs=-1, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fitting the grid searches to the training data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 14 candidates, totalling 140 fits\n",
      "[Pipeline] .... (step 1 of 3) Processing standardscaler, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing minmaxscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing decisiontreeclassifier, total=   0.0s\n",
      "DecisionTreeRegressor:\n",
      "Best Training Score: 0.5475\n",
      "Best Parameters: {'decisiontreeclassifier__criterion': 'gini', 'decisiontreeclassifier__max_depth': 8}\n",
      "Best Testing Score: 0.5441176470588235\n",
      "\n",
      "Fitting 10 folds for each of 110 candidates, totalling 1100 fits\n",
      "[Pipeline] .... (step 1 of 3) Processing standardscaler, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing minmaxscaler, total=   0.0s\n",
      "[Pipeline]  (step 3 of 3) Processing randomforestclassifier, total=   0.7s\n",
      "RandomForestRegressor:\n",
      "Best Training Score: 0.6066666666666667\n",
      "Best Parameters: {'randomforestclassifier__criterion': 'entropy', 'randomforestclassifier__max_depth': 300, 'randomforestclassifier__n_estimators': 550}\n",
      "Best Testing Score: 0.5735294117647058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 140 out of 140 | elapsed:    0.6s finished\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/model_selection/_split.py:672: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1100 out of 1100 | elapsed:  2.2min finished\n"
     ]
    }
   ],
   "source": [
    "gs_dt.fit(x_train, y_train)\n",
    "print(\"DecisionTreeRegressor:\")\n",
    "print(\"Best Training Score:\", gs_dt.best_score_)\n",
    "print(\"Best Parameters:\", gs_dt.best_params_)\n",
    "print(\"Best Testing Score:\", gs_dt.score(x_test, y_test))\n",
    "print()\n",
    "\n",
    "gs_rf.fit(x_train, y_train)\n",
    "print(\"RandomForestRegressor:\")\n",
    "print(\"Best Training Score:\", gs_rf.best_score_)\n",
    "print(\"Best Parameters:\", gs_rf.best_params_)\n",
    "print(\"Best Testing Score:\", gs_rf.score(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Changing the dataset from the entire dataset to using the best features selected by Random Forest feature selection reduced\n",
    "the accuracy by about 5-6%. Therefore, we would like to use the original datset.\n",
    "\n",
    "Between 7 classifications, the probability of getting a correct classification by random chance is 14%. The best testing\n",
    "accuracy we have gotten is 63.2%. This, while being much better than guessing at classifying the schools into the correct\n",
    "pricing bracket, is still not great. We are beginning to believe that our dataset might be problematic in our quest to\n",
    "classify or predict college prices, however, this could be an interesting conclusion in that we might be able to say, with\n",
    "certainty, that the price of collect is more arbitrary than we may have previously thought.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}