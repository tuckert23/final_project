{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Final Project\n",
    "## Authors:\n",
    "- Taylor Tucker\n",
    "- Virginia Weston\n",
    "- Tina Jin\n",
    "- Jeffrey Bradley\n",
    "\n",
    "## Code for linear regression modeling, however using Ridge, Lasso, and ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import statements"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import RidgeCV, ElasticNetCV, LassoCV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importing the continuous dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./cleaned_data.csv\", index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making x, y, and best feature splits and creating the training and testing data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "x = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=True, random_state=1, test_size=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating a list of L1 ratios for ElasticNet grid search. The other two regressors do not really have hyperparameters,\n",
    "according to the documentation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "ratios = [0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1]\n",
    "grid = {\"elasticnetcv__l1_ratio\": ratios}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making the pipelines for the learners"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "pl_lasso = make_pipeline(StandardScaler(), MinMaxScaler(), LassoCV(normalize=True, cv=10, copy_X=True), verbose=True)\n",
    "pl_ridge = make_pipeline(StandardScaler(), MinMaxScaler(), RidgeCV(normalize=True, cv=10), verbose=True)\n",
    "pl_en = make_pipeline(StandardScaler(), MinMaxScaler(), ElasticNetCV(normalize=True, cv=10, copy_X=True), verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating a GridSearchCV for the ElasticNet Learner"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "gs_en = GridSearchCV(estimator=pl_en, param_grid=grid, n_jobs=-1, refit=True, cv=10, verbose=True, scoring='r2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fitting the pipelines for Lasso and Ridge, and fitting the GridSearch for ElasticNet."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .... (step 1 of 3) Processing standardscaler, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing minmaxscaler, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 3) Processing lassocv, total=   0.1s\n",
      "[Pipeline] .... (step 1 of 3) Processing standardscaler, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing minmaxscaler, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 3) Processing ridgecv, total=   0.1s\n",
      "Fitting 10 folds for each of 11 candidates, totalling 110 fits\n",
      "[Pipeline] .... (step 1 of 3) Processing standardscaler, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 3) Processing minmaxscaler, total=   0.0s\n",
      "[Pipeline] ...... (step 3 of 3) Processing elasticnetcv, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3134163.6524910927, tolerance: 2991101.656582978\n",
      "  tol, rng, random, positive)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 110 out of 110 | elapsed:    3.1s finished\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3134163.6524910927, tolerance: 2991101.656582978\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=10,\n             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n                                       ('minmaxscaler', MinMaxScaler()),\n                                       ('elasticnetcv',\n                                        ElasticNetCV(cv=10, normalize=True))],\n                                verbose=True),\n             n_jobs=-1,\n             param_grid={'elasticnetcv__l1_ratio': [0, 0.1, 0.2, 0.3, 0.4, 0.5,\n                                                    0.6, 0.7, 0.8, 0.9, 1]},\n             scoring='r2', verbose=True)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_lasso.fit(x_train, y_train)\n",
    "pl_ridge.fit(x_train, y_train)\n",
    "gs_en.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Printing the R^2 Accuracies of the models, including the GridSearchCV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Testing R^2: 0.8404422713790248\n",
      "Ridge Testing R^2: 0.8244072494805195\n",
      "ElasticNet Testing R^2: 0.8404422713790248\n",
      "ElasticNet Best Training Score: 0.7950507307111627\n",
      "ElasticNet Best Params: {'elasticnetcv__l1_ratio': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Lasso Testing R^2:\", pl_lasso.score(x_test, y_test))\n",
    "print(\"Ridge Testing R^2:\", pl_ridge.score(x_test, y_test))\n",
    "print(\"ElasticNet Testing R^2:\", gs_en.score(x_test, y_test))\n",
    "print(\"ElasticNet Best Training Score:\", gs_en.best_score_)\n",
    "print(\"ElasticNet Best Params:\", gs_en.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, there are not much better accuracies than the normal logistic regression. I still want to try to exact\n",
    "same process, however, with the MaxAbsScaler instead to conserve spatial relationships."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./cleaned_data.csv\", index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making x, y, and best feature splits and creating the training and testing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "x = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=True, random_state=1, test_size=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating a list of L1 ratios for ElasticNet grid search. The other two regressors do not really have hyperparameters,\n",
    "according to the documentation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "ratios = [0, .1, .2, .3, .4, .5, .6, .7, .8, .9, 1]\n",
    "grid = {\"elasticnetcv__l1_ratio\": ratios}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making the pipelines for the learners"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "pl_lasso = make_pipeline(MaxAbsScaler(), LassoCV(normalize=True, cv=10, copy_X=True), verbose=True)\n",
    "pl_ridge = make_pipeline(MaxAbsScaler(), RidgeCV(normalize=True, cv=10), verbose=True)\n",
    "pl_en = make_pipeline(MaxAbsScaler(), ElasticNetCV(normalize=True, cv=10, copy_X=True), verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating a GridSearchCV for the ElasticNet Learner"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "gs_en = GridSearchCV(estimator=pl_en, param_grid=grid, n_jobs=-1, refit=True, cv=10, verbose=True, scoring='r2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fitting the pipelines for Lasso and Ridge, and fitting the GridSearch for ElasticNet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ...... (step 1 of 2) Processing maxabsscaler, total=   0.0s\n",
      "[Pipeline] ........... (step 2 of 2) Processing lassocv, total=   0.1s\n",
      "[Pipeline] ...... (step 1 of 2) Processing maxabsscaler, total=   0.0s\n",
      "[Pipeline] ........... (step 2 of 2) Processing ridgecv, total=   0.0s\n",
      "Fitting 10 folds for each of 11 candidates, totalling 110 fits\n",
      "[Pipeline] ...... (step 1 of 2) Processing maxabsscaler, total=   0.0s\n",
      "[Pipeline] ...... (step 2 of 2) Processing elasticnetcv, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3134163.6525239944, tolerance: 2991101.656582978\n",
      "  tol, rng, random, positive)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  95 out of 110 | elapsed:    2.1s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 110 out of 110 | elapsed:    2.5s finished\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/_coordinate_descent.py:527: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3134163.6525239944, tolerance: 2991101.656582978\n",
      "  tol, rng, random, positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": "GridSearchCV(cv=10,\n             estimator=Pipeline(steps=[('maxabsscaler', MaxAbsScaler()),\n                                       ('elasticnetcv',\n                                        ElasticNetCV(cv=10, normalize=True))],\n                                verbose=True),\n             n_jobs=-1,\n             param_grid={'elasticnetcv__l1_ratio': [0, 0.1, 0.2, 0.3, 0.4, 0.5,\n                                                    0.6, 0.7, 0.8, 0.9, 1]},\n             scoring='r2', verbose=True)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl_lasso.fit(x_train, y_train)\n",
    "pl_ridge.fit(x_train, y_train)\n",
    "gs_en.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Printing the R^2 Accuracies of the models, including the GridSearchCV"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Testing R^2: 0.8404422713790247\n",
      "Ridge Testing R^2: 0.8244072494805194\n",
      "ElasticNet Testing R^2: 0.8404422713790247\n",
      "ElasticNet Best Training Score: 0.7950507307111628\n",
      "ElasticNet Best Params: {'elasticnetcv__l1_ratio': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Lasso Testing R^2:\", pl_lasso.score(x_test, y_test))\n",
    "print(\"Ridge Testing R^2:\", pl_ridge.score(x_test, y_test))\n",
    "print(\"ElasticNet Testing R^2:\", gs_en.score(x_test, y_test))\n",
    "print(\"ElasticNet Best Training Score:\", gs_en.best_score_)\n",
    "print(\"ElasticNet Best Params:\", gs_en.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Absolutely no difference in R^2 values. Since the Lasso seems to be the best model, I will use that on the best features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./cleaned_data.csv\", index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making x, y, and best feature splits and creating the training and testing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "x = df[[\"Average Amount of Aid\", \"Graduation Rate\"]]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=True, random_state=1, test_size=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making the new pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pl_lasso = make_pipeline(MaxAbsScaler(), LassoCV(normalize=True, verbose=True, cv=10, copy_X=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fitting the pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pl_lasso.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": "Pipeline(steps=[('maxabsscaler', MaxAbsScaler()),\n                ('lassocv', LassoCV(cv=10, normalize=True, verbose=True))])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Printing the R^2 testing score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso with the best two features and MaxAbsScaler Accuracy: 0.8464922187631583\n"
     ]
    }
   ],
   "source": [
    "print(\"Lasso with the best two features and MaxAbsScaler Accuracy:\", pl_lasso.score(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the best two features (i.e. the two that are most correlated with the target, we get a testing accuracy of 84.6%,\n",
    "even with L2 Normalization and feature scaling. I would argue this is one of the best models we have."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}